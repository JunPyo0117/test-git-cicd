name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  AWS_REGION: ap-northeast-2
  ECR_REPOSITORY_NAME: cicd-demo
  EKS_CLUSTER_NAME: cicd-cluster
  # ALB가 퍼블릭 서브넷에 위치함을 명시
  ALB_SCHEME: internet-facing

permissions:
  id-token: write
  contents: read

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
    
    - name: Install Frontend Dependencies
      working-directory: ./frontend
      run: npm ci
    
    - name: Install Backend Dependencies
      working-directory: ./backend
      run: npm ci

  build-and-deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    # AWS 자격 증명 구성 (OIDC 방식)
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::471303021447:role/github-actions-role
        aws-region: ${{ env.AWS_REGION }}
        role-session-name: github-actions-${{ github.run_id }}
        role-duration-seconds: 3600
    
    # ECR 로그인
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
    
    # 백엔드 빌드 및 푸시
    - name: Build and push Backend image
      working-directory: ./backend
      run: |
        npm ci
        npm run build
        docker build -t backend .
        docker tag backend:latest ${{ steps.login-ecr.outputs.registry }}/cicd-demo-backend:latest
        docker push ${{ steps.login-ecr.outputs.registry }}/cicd-demo-backend:latest
    
    # 프론트엔드 빌드 및 푸시
    - name: Build and push Frontend image
      working-directory: ./frontend
      env:
        # 상대 경로를 사용하여 같은 도메인의 /api로 요청
        VITE_API_URL: "/api"
      run: |
        npm ci
        npm run build
        # Force rebuild with no cache to ensure nginx.conf changes are included
        docker build --no-cache -t frontend .
        docker tag frontend:latest ${{ steps.login-ecr.outputs.registry }}/cicd-demo-frontend:latest
        docker push ${{ steps.login-ecr.outputs.registry }}/cicd-demo-frontend:latest
    
    # EKS 설정 및 Access Entries 적용
    - name: Configure EKS access
      run: |
        aws eks update-kubeconfig --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }}
        aws sts get-caller-identity
        
        # Check if EKS cluster is accessible via AWS CLI
        echo "Checking EKS cluster accessibility..."
        if aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }} > /dev/null 2>&1; then
          echo "EKS cluster is accessible via AWS CLI"
        else
          echo "Cannot access EKS cluster via AWS CLI"
          exit 1
        fi
        
        # Get current AWS identity
        CURRENT_ARN=$(aws sts get-caller-identity --query 'Arn' --output text)
        echo "Current AWS ARN: $CURRENT_ARN"
        
        # Create EKS Access Entry for GitHub Actions role
        echo "Creating EKS Access Entry for GitHub Actions role..."
        aws eks create-access-entry \
          --cluster-name ${{ env.EKS_CLUSTER_NAME }} \
          --region ${{ env.AWS_REGION }} \
          --principal-arn "arn:aws:iam::471303021447:role/github-actions-role" \
          --type Standard \
          --kubernetes-groups system:masters || {
          echo "Access entry creation failed or already exists"
        }
        
        # Test kubectl access
        kubectl get nodes
    
    # AWS Load Balancer Controller ServiceAccount 생성
    - name: Create AWS Load Balancer Controller ServiceAccount
      run: |
        cat > aws-load-balancer-controller-sa.yaml << EOF
        apiVersion: v1
        kind: ServiceAccount
        metadata:
          name: aws-load-balancer-controller
          namespace: kube-system
          annotations:
            eks.amazonaws.com/role-arn: arn:aws:iam::471303021447:role/aws-load-balancer-controller
        EOF
        kubectl apply -f aws-load-balancer-controller-sa.yaml --validate=false
    
    # AWS Load Balancer Controller 설치
    - name: Install AWS Load Balancer Controller
      run: |
        # Helm을 사용하여 AWS Load Balancer Controller 설치
        helm repo add eks https://aws.github.io/eks-charts
        helm repo update
        
        # VPC ID 가져오기
        VPC_ID=$(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --query 'cluster.resourcesVpcConfig.vpcId' --output text)
        echo "VPC ID: $VPC_ID"
        
        # AWS Load Balancer Controller 설치 (기존 설치가 있다면 업그레이드)
        helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
          -n kube-system \
          --set clusterName=${{ env.EKS_CLUSTER_NAME }} \
          --set serviceAccount.create=false \
          --set serviceAccount.name=aws-load-balancer-controller \
          --set region=${{ env.AWS_REGION }} \
          --set vpcId=$VPC_ID \
          --wait --timeout=300s
        
        # Controller가 준비될 때까지 대기
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=aws-load-balancer-controller -n kube-system --timeout=300s
    
    # 환경 변수 설정
    - name: Set environment variables
      run: |
        echo "ECR_REGISTRY=${{ steps.login-ecr.outputs.registry }}" >> $GITHUB_ENV
        echo "IMAGE_TAG=latest" >> $GITHUB_ENV
        
        # DOMAIN_NAME 처리 (비어있으면 ALB DNS만 사용)
        DOMAIN_NAME="${{ secrets.DOMAIN_NAME }}"
        if [ -z "$DOMAIN_NAME" ] || [ "$DOMAIN_NAME" = "" ]; then
          echo "DOMAIN_NAME is empty, will use ALB DNS only"
          echo "USE_DOMAIN=false" >> $GITHUB_ENV
          echo "DOMAIN_NAME=" >> $GITHUB_ENV
          # 상대 경로를 사용하므로 API_URL은 /api로 설정
          echo "API_URL=/api" >> $GITHUB_ENV
        else
          echo "DOMAIN_NAME=$DOMAIN_NAME" >> $GITHUB_ENV
          echo "USE_DOMAIN=true" >> $GITHUB_ENV
          echo "API_URL=/api" >> $GITHUB_ENV
        fi
        
        # Terraform output에서 서브넷 ID와 보안 그룹 ID 가져오기
        PUBLIC_SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=tag:Name,Values=*public*" "Name=vpc-id,Values=$(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --query 'cluster.resourcesVpcConfig.vpcId' --output text)" --query 'Subnets[*].SubnetId' --output text | tr '\t' ',')
        ALB_SECURITY_GROUP_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=*alb*" "Name=vpc-id,Values=$(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --query 'cluster.resourcesVpcConfig.vpcId' --output text)" --query 'SecurityGroups[0].GroupId' --output text)
        
        echo "PUBLIC_SUBNET_IDS=$PUBLIC_SUBNET_IDS" >> $GITHUB_ENV
        echo "ALB_SECURITY_GROUP_ID=$ALB_SECURITY_GROUP_ID" >> $GITHUB_ENV
    
    # 데이터베이스 시크릿 생성
    - name: Create database secret
      run: |
        # RDS 정보 설정 (Terraform output에서 가져온 값)
        DB_HOST="cicd-database.cvuok60y0zyf.ap-northeast-2.rds.amazonaws.com"
        DB_PASSWORD="LmxrTJyUnp00uR1j"
        
        echo "Creating database secret..."
        echo "DB_HOST: $DB_HOST"
        echo "DB_PASSWORD: [HIDDEN]"
        
        # kubectl을 사용하여 직접 시크릿 생성 (기존 시크릿이 있으면 삭제 후 재생성)
        kubectl delete secret db-secret -n cicd-demo --ignore-not-found=true
        
        kubectl create secret generic db-secret \
          --namespace=cicd-demo \
          --from-literal=host="$DB_HOST" \
          --from-literal=port="5432" \
          --from-literal=username="postgres" \
          --from-literal=password="$DB_PASSWORD" \
          --from-literal=database="cicd_demo"
        
        echo "Secret created successfully using kubectl"
        
        # 시크릿 확인
        kubectl get secret db-secret -n cicd-demo -o yaml
    
    # Kubernetes 매니페스트 적용
    - name: Deploy to EKS
      run: |
        # 환경 변수 치환
        envsubst < k8s/backend/deployment.yaml > k8s/backend/deployment-generated.yaml
        envsubst < k8s/frontend/deployment.yaml > k8s/frontend/deployment-generated.yaml
        envsubst < k8s/configmap.yaml > k8s/configmap-generated.yaml
        
        # Ingress 생성 (도메인 사용 여부에 따라 다르게 처리)
        echo "=== Ingress Generation Debug ==="
        echo "USE_DOMAIN: $USE_DOMAIN"
        echo "DOMAIN_NAME: $DOMAIN_NAME"
        echo "PUBLIC_SUBNET_IDS: $PUBLIC_SUBNET_IDS"
        echo "ALB_SECURITY_GROUP_ID: $ALB_SECURITY_GROUP_ID"
        
        if [ "$USE_DOMAIN" = "true" ]; then
          echo "Creating Ingress with domain: $DOMAIN_NAME"
          envsubst < k8s/ingress.yaml > k8s/ingress-generated.yaml
          echo "Ingress file created from template"
        else
          echo "Creating Ingress without domain (ALB DNS only)"
          cat > k8s/ingress-generated.yaml << 'EOF'
        apiVersion: networking.k8s.io/v1
        kind: Ingress
        metadata:
          name: cicd-ingress
          namespace: cicd-demo
          annotations:
            kubernetes.io/ingress.class: "alb"
            alb.ingress.kubernetes.io/scheme: "internet-facing"
            alb.ingress.kubernetes.io/target-type: "ip"
            alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}]'
            alb.ingress.kubernetes.io/group.name: "cicd-demo"
            alb.ingress.kubernetes.io/group.order: "1"
            alb.ingress.kubernetes.io/healthcheck-path: "/"
            alb.ingress.kubernetes.io/healthcheck-port: "80"
            alb.ingress.kubernetes.io/healthcheck-protocol: "HTTP"
            alb.ingress.kubernetes.io/success-codes: "200"
            alb.ingress.kubernetes.io/cors-allow-origin: "*"
            alb.ingress.kubernetes.io/cors-allow-methods: "GET, POST, PUT, DELETE, OPTIONS"
            alb.ingress.kubernetes.io/cors-allow-headers: "*"
            alb.ingress.kubernetes.io/cors-expose-headers: "*"
            alb.ingress.kubernetes.io/cors-max-age: "600"
        EOF
          # 환경 변수 치환으로 서브넷과 보안 그룹 추가
          cat >> k8s/ingress-generated.yaml << EOF
            alb.ingress.kubernetes.io/subnets: "${PUBLIC_SUBNET_IDS}"
            alb.ingress.kubernetes.io/security-groups: "${ALB_SECURITY_GROUP_ID}"
        spec:
          ingressClassName: alb
          rules:
          # ALB DNS로만 접근 (도메인 없음)
          - http:
              paths:
              - path: /
                pathType: Prefix
                backend:
                  service:
                    name: frontend-service
                    port:
                      number: 80
              - path: /api
                pathType: Prefix
                backend:
                  service:
                    name: backend-service
                    port:
                      number: 80
        EOF
        fi
        
        # Ingress 파일 생성 확인
        echo "=== Ingress File Check ==="
        if [ -f "k8s/ingress-generated.yaml" ]; then
          echo "✅ Ingress file created successfully"
          echo "File size: $(wc -c < k8s/ingress-generated.yaml) bytes"
          echo "First 10 lines of Ingress file:"
          head -10 k8s/ingress-generated.yaml
        else
          echo "❌ Ingress file not found!"
          exit 1
        fi
        
        # 배포 (각 단계별로 확인)
        echo "Creating namespace..."
        kubectl apply -f k8s/namespace.yaml
        
        echo "Applying ConfigMap..."
        kubectl apply -f k8s/configmap-generated.yaml
        
        echo "Database secret already created in previous step..."
        
        echo "Deploying backend..."
        kubectl apply -f k8s/backend/deployment-generated.yaml
        kubectl apply -f k8s/backend/service.yaml
        
        echo "Deploying frontend..."
        # 기존 CrashLoopBackOff pod들을 강제로 정리
        echo "Cleaning up any stuck pods..."
        kubectl delete pods -n cicd-demo -l app=frontend --force --grace-period=0 || true
        
        kubectl apply -f k8s/frontend/deployment-generated.yaml
        kubectl apply -f k8s/frontend/service.yaml
        
        echo "Applying Ingress..."
        echo "=== Ingress Apply Debug ==="
        kubectl apply -f k8s/ingress-generated.yaml
        echo "Ingress applied successfully"
        
        # Ingress 상태 확인
        echo "=== Ingress Status Check ==="
        kubectl get ingress -n cicd-demo
        echo "Ingress details:"
        kubectl describe ingress cicd-ingress -n cicd-demo
        
        # 배포 상태 확인
        echo "Waiting for backend deployment to be ready..."
        kubectl rollout status deployment/backend -n cicd-demo --timeout=300s
        
        echo "Checking backend pods status..."
        kubectl get pods -n cicd-demo -l app=backend
        
        echo "Waiting for frontend deployment to be ready..."
        if ! kubectl rollout status deployment/frontend -n cicd-demo --timeout=300s; then
          echo "Frontend deployment failed! Debugging..."
          
          echo "=== Frontend Deployment Status ==="
          kubectl describe deployment frontend -n cicd-demo
          
          echo "=== Frontend Pod Status ==="
          kubectl get pods -n cicd-demo -l app=frontend
          
          echo "=== Frontend Pod Events ==="
          kubectl get events -n cicd-demo --field-selector involvedObject.kind=Pod --sort-by='.lastTimestamp'
          
          echo "=== Frontend Pod Logs ==="
          for pod in $(kubectl get pods -n cicd-demo -l app=frontend -o jsonpath='{.items[*].metadata.name}'); do
            echo "--- Pod: $pod ---"
            echo "Current logs:"
            kubectl logs $pod -n cicd-demo --tail=100 || echo "No current logs available for $pod"
            echo "Previous logs (if any):"
            kubectl logs $pod -n cicd-demo --previous --tail=100 || echo "No previous logs available for $pod"
            echo "--- Pod Description: $pod ---"
            kubectl describe pod $pod -n cicd-demo
          done
          
          echo "=== ECR Image Check ==="
          echo "Frontend image: ${ECR_REGISTRY}/cicd-demo-frontend:${IMAGE_TAG}"
          
          exit 1
        fi
        
        # Ingress 상태 확인 및 ALB DNS 출력
        echo "Waiting for Ingress to be ready..."
        kubectl wait --for=condition=ready ingress/cicd-ingress -n cicd-demo --timeout=300s
        
        # ALB DNS 이름 출력
        ALB_DNS=$(kubectl get ingress cicd-ingress -n cicd-demo -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
        echo "ALB DNS Name: $ALB_DNS"
        
        # 프론트엔드는 상대 경로 (/api)를 사용하므로 재배포 불필요
        echo "Frontend uses relative API path (/api), no redeployment needed"
        
        if [ "$USE_DOMAIN" = "true" ]; then
          echo "Frontend URL: https://$DOMAIN_NAME"
          echo "Backend API URL: https://api.$DOMAIN_NAME"
          echo "ALB Direct Access: http://$ALB_DNS"
        else
          echo "Frontend URL: http://$ALB_DNS"
          echo "Backend API URL: http://$ALB_DNS/api"
          echo "Note: No custom domain configured. Access via ALB DNS only."
        fi
